{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Comptuer Vision\n",
    "A very brief overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Comments here)\n",
    "\n",
    "## Computer Vision Tasks\n",
    "\n",
    "* Digital Image Accusation\n",
    "* 3D Reconstruction\n",
    "* Object Detection\n",
    "* Recognition\n",
    "* Sementic Segmentation\n",
    "* Tracking\n",
    "* ...\n",
    "\n",
    "To expapolate and make decisions, you will need **knowledge**.\n",
    "\n",
    "How to pass knowledge to machines? Human enforced rules? Not a good idea ...\n",
    "\n",
    "Better go for **Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "### What is machine learning\n",
    "Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\n",
    "\n",
    "* Supervised learning\n",
    "* Unsupervised learning\n",
    "* Reinforcement learning\n",
    "* ...\n",
    "\n",
    "Let's just take a supervised image classification task (which is relevant to what we do!).\n",
    "\n",
    "### How to do machine learning (supervised image classification task)\n",
    "\n",
    "Think about how you would distinguish a sunflower and a red rose by looking at them.\n",
    "\n",
    "How would you discribe them?\n",
    "\n",
    "What if we only consider colour and size as our **features**.\n",
    "\n",
    "| Feature | **Colour** | **Size** |\n",
    "| --- | --- | --- |\n",
    "| **Sunflower** | Yellow | Big |\n",
    "| **Red Rose** | Red | Small |\n",
    "\n",
    "**Features in ML:** An individual measurable property or characteristic of a phenomenon being observed.\n",
    "\n",
    "If we quantify our selected features and plot each sample / observation as a point in 2D space\n",
    "\n",
    "![SVM_1](./img/simple_2d_fpts.png)\n",
    "\n",
    "Time to choose our **classifer**.\n",
    "\n",
    "* Bayesian Model\n",
    "* Support Vector Machines (SVMs)\n",
    "* Random Forest\n",
    "* Markov Chain\n",
    "* Neural Network\n",
    "* ...\n",
    "\n",
    "By observing the distribution of the samples, we learned that they are **linearly separable**, meaning we can classify them by drawing a line.\n",
    "\n",
    "In this case, we can comfortably choose a **Linear SVM** classifier to do the job. \n",
    "\n",
    "[//]: # (Explain SVM a little more with the figure)\n",
    "\n",
    "[Link: Using SVM in OpenCV](https://docs.opencv.org/3.4/d1/d73/tutorial_introduction_to_svm.html) \n",
    "\n",
    "![SVM_2](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Svm_max_sep_hyperplane_with_margin.png/557px-Svm_max_sep_hyperplane_with_margin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in real life, data is messy and not always linearly separable. For example, what if we have data distributed in the form of two circles like this.\n",
    "\n",
    "![two_circles](./img/non-linearly-separable-data.jpg)\n",
    "\n",
    "Can we still use SVMs? The answer is YES!\n",
    "\n",
    "To accomplish this, we use a technique called the **Kernel Trick**. What a kernel does is mapping the features to a higher dimensional space in which they are linerly separable. In the two circle case, let's add a third dimension using the equation\n",
    "$z=e^{-\\gamma(x^2+y^2)}$, which is a **Radial Basis Function (RBF)** with a **Gaussian Kernel**. Then we plot the points with $z$ in a 3D space.\n",
    "\n",
    "![two_circles_3d](./img/kernel-trick.jpg)\n",
    "\n",
    "Now, they can be easily separated by a plane. Linear separability achieved and we can use SVMs again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vs. Classifier\n",
    "\n",
    "* Nice and clean features + simple classifier\n",
    "* Messy features + more advanced classifier\n",
    "\n",
    "Real-world problem is a lot messier and good features require careful engineering by domain experts and ML experts.\n",
    "To work with messy features, we need classifiers that can handle more complexed mapping.\n",
    "\n",
    "### Neural Network\n",
    "Let's have a look at a **Neural Network**, a computational graph that can approximate arbitrary complex functions.\n",
    "\n",
    "[Link: Neural nets can compute any function](http://neuralnetworksanddeeplearning.com/chap4.html)\n",
    "\n",
    "![ANN](https://msatechnosoft.in/blog/wp-content/uploads/2018/05/Biological-vs-artificial-neuron-MSA-Technosoft.jpeg)\n",
    "\n",
    "**How does a Nerual Net work?**\n",
    "\n",
    "![bin](./img/bin_activate.png)\n",
    "\n",
    "![bin](./img/sigmod_activate.png)\n",
    "\n",
    "![bin](./img/layers.png)\n",
    "\n",
    "![bin](./img/layers_matrix.png)\n",
    "\n",
    "Neural Network warp the feature space, mapping the input data to another space where it is easy to handle. \n",
    "\n",
    "![warp](./img/ann_warp.png)\n",
    "\n",
    "What a Neural Net essentially learned is a mapping from the input space to the output space, aka **A Function**.\n",
    "\n",
    "It learns the mapping by adjusting the weights and biases through backpropagation.\n",
    "\n",
    "[Video: How Neural Networks bend the feature space](https://www.youtube.com/watch?v=vdqu6fvjc5c)\n",
    "\n",
    "[Video: What is backpropagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n",
    "\n",
    "BTW, think about a one-layer Neural Network vs. a Linear SVM, are they equal?\n",
    "\n",
    "OK, now we know there are more advanced classifiers.\n",
    "\n",
    "But...\n",
    "\n",
    "Real world is messy, what if we don't know how to construct our features.\n",
    "If a NN can learn a desired mapping, can it learn how to build the features too.\n",
    "The answer is again YES!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (CNN)\n",
    "\n",
    "First, what is convolution? \n",
    "[Link: A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
    "\n",
    "More details on convolution: [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285)\n",
    "\n",
    "Consider convolution as a mapping from input data to feature vectors.\n",
    "\n",
    "Pooling, a subsampling to reduce the demention of feature vector.\n",
    "\n",
    "A typical figure of CNN, from LeCun Yann's hand-written digit (MNIST dataset) recognition using a CNN.\n",
    "![CNN](https://www.kdnuggets.com/wp-content/uploads/cnn-architecture.jpg)\n",
    "\n",
    "[Video: Convolutional neural network kernels during training on MNIST dataset](https://www.youtube.com/watch?v=VUkFo6IXMJc)\n",
    "\n",
    "Features vs. Classifiers (looks familiar?)\n",
    "\n",
    "The native models (LeNet) only contains a few (single digit number) thousand free parameters to be tuned. After trained, it can reach over 90% accuracy on MNIST dataset.\n",
    "[Link to MNIST dataset](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "AlexNet, winner of the ImageNet Chanllenge in 2012 has 5 Convolutional Layers and 3 Fully Connected Layers, which gives over 60 million \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "What to do with small training dataset\n",
    "how to construct data for training / validation\n",
    "tricks in ...\n",
    "\n",
    "classifier fit the data\n",
    "\n",
    "\n",
    "how to select your classifier\n",
    "how to leverage deep learning frameworks\n",
    "what is transfer learning\n",
    "why transfer learning could work\n",
    "\n",
    "when to stop training\n",
    "training, validation, testing\n",
    "70, 20, 10\n",
    "60, 20, 20\n",
    "Training set: A set of examples used for learning, that is to fit the parameters [i.e., weights] of the classifier.\n",
    "\n",
    "Validation set: A set of examples used to tune the parameters [i.e., architecture, not weights] of a classifier, for example to choose the number of hidden units in a neural network.\n",
    "\n",
    "Test set: A set of examples used only to assess the performance [generalization] of a fully specified classifier.\n",
    "\n",
    "\n",
    "Applied deep learning research is much more about taming your problem (understanding the inputs and outputs), casting the problem as a supervised learning problem, and hammering it with ample data and ample experiments.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Link: Deep Learning Review](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)\n",
    "\n",
    "[The Deep Learning Book](http://www.deeplearningbook.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision\n",
    "### Reconstruction\n",
    "Perception\n",
    "Perceve the world, \n",
    "\n",
    "The very native and ... task for computer vision.\n",
    "![SfM](http://openmvg.readthedocs.org/en/latest/_images/structureFromMotion.png \"Structure from Motion\")\n",
    "![SfM](http://www.cs.cornell.edu/~snavely/bundler/images/Colosseum.jpg \"Structure from Motion\")\n",
    "\n",
    "3D reconstruction\n",
    "\n",
    "tracking\n",
    "\n",
    "### Recognition\n",
    "A higher level task ...\n",
    "recognition\n",
    "classification\n",
    "detection\n",
    "segmentation, sementic segmentation\n",
    "tracking\n",
    "\n",
    "Logical\n",
    "\n",
    "\n",
    "most contemporary AI researchers agree that Logic-based AI is dead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning (Excluding Deep Learning)\n",
    "\n",
    "Relation between machine learning and deep learning.\n",
    "![](https://cdn-images-1.medium.com/max/1200/1*TiORvHgrJPme_lEiX3olVA.png)\n",
    "\n",
    "### Feature / Descriptor\n",
    "\n",
    "\n",
    "[From feature descriptors to deep learning: 20 years of computer vision](http://www.computervisionblog.com/2015/01/from-feature-descriptors-to-deep.html)\n",
    "\n",
    "\n",
    "### Classifier\n",
    "\n",
    "SVM\n",
    "Random Forest\n",
    "Neural Networks\n",
    "\n",
    "\n",
    "### Supervised and Unsupervised Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning (the hottest part now in ML)\n",
    "\n",
    "[I'm an inline-style link](https://www.google.com)\n",
    "\n",
    "Big data + deep model\n",
    "![](http://3.bp.blogspot.com/-zQlQvmK9U9g/VT_Hk6yKlmI/AAAAAAAAODQ/nNNcpVM4UPM/s1600/bg_pipeline-01.png)\n",
    "\n",
    "\n",
    "### Model\n",
    "\n",
    "nueron\n",
    "activate function\n",
    "sigmod\n",
    "tanh\n",
    "reLu\n",
    "maxout\n",
    "\n",
    "\n",
    "\n",
    "CNN\n",
    "Convlutional \n",
    "\n",
    "what is convolution\n",
    "\n",
    "convlution in math\n",
    "kernel/filter\n",
    "convlution as a matrix operation\n",
    "\n",
    "an example\n",
    "canny filter for edge\n",
    "\n",
    "\n",
    "How learn\n",
    "Back propgation\n",
    "Gradent decent\n",
    "\n",
    "how a NN warp and transform the feature space\n",
    "a neuron --- linear classifer\n",
    "\n",
    "\n",
    "\n",
    "[Neural nets can compute any function](http://neuralnetworksanddeeplearning.com/chap4.html)\n",
    "[]()\n",
    "[]()\n",
    "\n",
    "\n",
    "### Implementation / Coding\n",
    "\n",
    "[SVM OpenCV](https://docs.opencv.org/3.4/d1/d73/tutorial_introduction_to_svm.html) \n",
    "Random Forest OpenCV\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Frameworks / Libraries\n",
    "\n",
    "![](https://agi.io/wp-content/uploads/2018/02/frameworks-new.png)\n",
    "\n",
    "\n",
    "Trend\n",
    "![](https://pbs.twimg.com/media/DX5I8r_VwAACbmo.jpg:large)\n",
    "\n",
    "Use Tensorflow + Keras\n",
    "\n",
    "bigger data + deeper model\n",
    "\n",
    "\n",
    "For data, how big is big enough?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wordpress.viu.ca/ciel/files/2013/01/134992626.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
