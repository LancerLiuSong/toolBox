{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Comptuer Vision\n",
    "A very brief overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Comments here)\n",
    "\n",
    "## Computer Vision Tasks\n",
    "\n",
    "* Digital Image Accusation\n",
    "* 3D Reconstruction\n",
    "* Object Detection\n",
    "* Recognition\n",
    "* Sementic Segmentation\n",
    "* Tracking\n",
    "* ...\n",
    "\n",
    "To expapolate and make decisions, you will need **knowledge**.\n",
    "\n",
    "How to pass knowledge to machines? Human enforced rules? Not a good idea ...\n",
    "\n",
    "Better go for **Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "### What is machine learning\n",
    "Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\n",
    "\n",
    "* Supervised learning\n",
    "* Unsupervised learning\n",
    "* Reinforcement learning\n",
    "* ...\n",
    "\n",
    "Let's just take a supervised image classification task (which is relevant to what we do!).\n",
    "\n",
    "### How to do machine learning (supervised image classification task)\n",
    "\n",
    "Think about how you would distinguish a sunflower and a red rose by looking at them.\n",
    "\n",
    "How would you discribe them?\n",
    "\n",
    "What if we only consider colour and size as our **features**.\n",
    "\n",
    "| Feature | **Colour** | **Size** |\n",
    "| --- | --- | --- |\n",
    "| **Sunflower** | Yellow | Big |\n",
    "| **Red Rose** | Red | Small |\n",
    "\n",
    "**Features in ML:** An individual measurable property or characteristic of a phenomenon being observed.\n",
    "\n",
    "If we quantify our selected features and plot each sample / observation as a point in 2D space\n",
    "\n",
    "![SVM_1](./img/simple_2d_fpts.png)\n",
    "\n",
    "Time to choose our **classifer**.\n",
    "\n",
    "* Bayesian Model\n",
    "* Support Vector Machines (SVMs)\n",
    "* Random Forest\n",
    "* Markov Chain\n",
    "* Neural Network\n",
    "* ...\n",
    "\n",
    "By observing the distribution of the samples, we learned that they are **linearly separable**, meaning we can classify them by drawing a line.\n",
    "\n",
    "In this case, we can comfortably choose a **Linear SVM** classifier to do the job. \n",
    "\n",
    "[//]: # (Explain SVM a little more with the figure)\n",
    "\n",
    "[Link: Using SVM in OpenCV](https://docs.opencv.org/3.4/d1/d73/tutorial_introduction_to_svm.html) \n",
    "\n",
    "![SVM_2](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Svm_max_sep_hyperplane_with_margin.png/557px-Svm_max_sep_hyperplane_with_margin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in real life, data is messy and not always linearly separable. For example, what if we have data distributed in the form of two circles like this.\n",
    "\n",
    "![two_circles](./img/non-linearly-separable-data.jpg)\n",
    "\n",
    "Can we still use SVMs? The answer is YES!\n",
    "\n",
    "To accomplish this, we use a technique called the **Kernel Trick**. What a kernel does is mapping the features to a higher dimensional space in which they are linerly separable. In the two circle case, let's add a third dimension using the equation\n",
    "$z=e^{-\\gamma(x^2+y^2)}$, which is a **Radial Basis Function (RBF)** with a **Gaussian Kernel**. Then we plot the points with $z$ in a 3D space.\n",
    "\n",
    "![two_circles_3d](./img/kernel-trick.jpg)\n",
    "\n",
    "Now, they can be easily separated by a plane. Linear separability achieved and we can use SVMs again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vs. Classifier\n",
    "\n",
    "* Nice and clean features + simple classifier\n",
    "* Messy features + more advanced classifier\n",
    "\n",
    "Real-world problem is a lot messier and good features require careful engineering by domain experts and ML experts.\n",
    "To work with messy features, we need classifiers that can handle more complexed mapping.\n",
    "\n",
    "### Neural Network\n",
    "Let's have a look at a **Neural Network**, a computational graph that can approximate arbitrary complex functions.\n",
    "\n",
    "[Link: Neural nets can compute any function](http://neuralnetworksanddeeplearning.com/chap4.html)\n",
    "\n",
    "![ANN](https://msatechnosoft.in/blog/wp-content/uploads/2018/05/Biological-vs-artificial-neuron-MSA-Technosoft.jpeg)\n",
    "\n",
    "How does a Nerual Net work? Take a closer look at an artifical neuron.\n",
    "\n",
    "![bin](./img/bin_activate.png)\n",
    "\n",
    "![bin](./img/sigmod_activate.png)\n",
    "\n",
    "![bin](./img/layers.png)\n",
    "\n",
    "![bin](./img/layers_matrix.png)\n",
    "\n",
    "Neural Network warps the feature space, mapping the input data to a space where it is easy to handle. \n",
    "\n",
    "![warp](./img/ann_warp.png)\n",
    "\n",
    "What a Neural Net essentially learned is a mapping from the input space to the output space, aka **A Function**.\n",
    "\n",
    "It learns the mapping by adjusting the weights and biases through gradient descent and backpropagation.\n",
    "\n",
    "![SGD](https://thumbs.gfycat.com/AngryInconsequentialDiplodocus-size_restricted.gif)\n",
    "\n",
    "[Video: How Neural Networks bend the feature space](https://www.youtube.com/watch?v=vdqu6fvjc5c)\n",
    "\n",
    "[Video: What is backpropagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n",
    "\n",
    "BTW, think about a one-layer Neural Network vs. a Linear SVM, are they equal?\n",
    "\n",
    "OK, now we know there are more advanced classifiers.\n",
    "\n",
    "But...\n",
    "\n",
    "Real world is messy, what if we don't know how to construct our features.\n",
    "If a NN can learn a desired mapping, can it learn how to build the features too.\n",
    "The answer is again YES!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (CNN)\n",
    "\n",
    "First, what is convolution? \n",
    "[Link: A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
    "\n",
    "More details on convolution: [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285)\n",
    "\n",
    "Consider convolution as a mapping from input data to feature vectors.\n",
    "\n",
    "Pooling, a subsampling to reduce the demention of feature vector.\n",
    "\n",
    "A typical structure of a CNN for image classification (LeNet), from LeCun Yann's paper on hand-written digit (MNIST dataset) recognition using a CNN.\n",
    "![CNN](https://www.kdnuggets.com/wp-content/uploads/cnn-architecture.jpg)\n",
    "\n",
    "[Video: Convolutional neural network kernels during training on MNIST dataset](https://www.youtube.com/watch?v=VUkFo6IXMJc)\n",
    "\n",
    "[Link: 3D visualisation of a train CNN using MNIST](http://scs.ryerson.ca/~aharley/vis/conv/)\n",
    "\n",
    "[Link: Feature visualisation](https://distill.pub/2017/feature-visualization/)\n",
    "\n",
    "Another re-structured CNN for image segmentation (SegNet).\n",
    "\n",
    "![segNet](http://mi.eng.cam.ac.uk/projects/segnet/images/segnet.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, why not Deep Learning for everyone?**\n",
    "\n",
    "Since we have DL, end-to-end models which can handle both feature extraction and classification, why not everyone keep using it every time.\n",
    "\n",
    "It's all about the data, more specifically the training data.\n",
    "\n",
    "![data_model](./img/data_model.png)\n",
    "\n",
    "The native models on MNIST (LeNet) only contains a few (single digit number) thousand free parameters to be tuned. It can reach over 90% accuracy on MNIST dataset, which contians 6000 training samples. [Link to MNIST dataset](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "AlexNet, winner of the Large Scale Visual Recognition Challenge (ILSVRC) 2012 has 5 Convolutional Layers and 3 Fully Connected Layers with over 60 million free parameters. The model was trained on the ImageNet dataset, a large hand-labeled image dataset (10,000,000 labeled images). [Link to ImageNet dataset](http://www.image-net.org/)\n",
    "\n",
    "**So, the more complex the better? Not really.** \n",
    "\n",
    "For example, AlexNet was huge in 2012, but in 2014 GoogLeNet came along with 12x fewer parameters, but far superior results.\n",
    "![googleNet](https://joelouismarino.github.io/images/blog_images/blog_googlenet_keras/googlenet_diagram.png)\n",
    "\n",
    "Now, the state-of-art CNN models are easily over 50 layers, some models like ResNet152 is over 150 layers.\n",
    "![resNet](https://cdn-images-1.medium.com/max/1314/1*S3TlG0XpQZSIpoDIUCQ0RQ.jpeg)\n",
    "\n",
    "![layers](https://deepage.net/img/resnet/resnet_top.jpg)\n",
    "\n",
    "Finding better network architectures to improve performance or achieve similar results using less data is a hot research topic in Deep Learning, Machine Learning and AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reday for some Deep Learning?\n",
    "\n",
    "Not core deep learning research, but maybe applied deep learning research.\n",
    "\n",
    "Applied deep learning research is much more about taming your problem (understanding the inputs and outputs), casting the problem as a supervised learning problem, and hammering it with ample data and ample experiments. --- Andrew Ng\n",
    "\n",
    "**Pick up the tools. learn them and use them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frameworks / Libraries\n",
    "\n",
    "**Tensorflow + Keras**\n",
    "\n",
    "![](https://agi.io/wp-content/uploads/2018/02/frameworks-new.png)\n",
    "![](https://pbs.twimg.com/media/DX5I8r_VwAACbmo.jpg:large)\n",
    "\n",
    "### Some coding\n",
    "\n",
    "* [Fashion MNIST using MLP](./tf_keras_fashionMNIST.ipynb)\n",
    "* [Fashion MNIST using CNN](./tf_keras_fashionMNIST_CNN.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some common questions about Machine Learning / Deep Learning\n",
    "\n",
    "**How to construct dataset for ML/DL?**\n",
    "\n",
    "Construct dataset for training, validation and testing (usually in the proportion of 70%, 20%, 10% or 60%, 20%, 20%).\n",
    "\n",
    "Training set: A set of examples used for learning, that is to fit the parameters [i.e., weights] of the classifier.\n",
    "\n",
    "Validation set: A set of examples used to tune the parameters [i.e., architecture, not weights] of a classifier, for example to choose the number of hidden units in a neural network.\n",
    "\n",
    "Test set: A set of examples used only to assess the performance [generalization] of a fully specified classifier.\n",
    "\n",
    "**How to measure the performance of a ML model?**\n",
    "\n",
    "* Alwasy pay more attention to validation and testing accuracy\n",
    "\n",
    "**When to stop training?**\n",
    "\n",
    "**What to do with small training dataset?**\n",
    "\n",
    "Try: \n",
    "* Data Enhancement\n",
    "* Cross Validation\n",
    "* Transfer Learning\n",
    "\n",
    "**How to avoid overfitting?**\n",
    "\n",
    "* Use dropout\n",
    "* Pay attention to training accuracy vs. validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Reading\n",
    "* [From feature descriptors to deep learning: 20 years of computer vision](http://www.computervisionblog.com/2015/01/from-feature-descriptors-to-deep.html)\n",
    "* [Deep Learning Review](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)\n",
    "* [The Deep Learning Book](http://www.deeplearningbook.org/)\n",
    "* [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)\n",
    "* [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision)\n",
    "* [Awesome - Most Cited Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
